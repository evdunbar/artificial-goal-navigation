{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 8924,
     "status": "ok",
     "timestamp": 1681777229210,
     "user": {
      "displayName": "Zhongqi Gao",
      "userId": "11577090512157430756"
     },
     "user_tz": 300
    },
    "id": "winZisG2Fx9f"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1681777229211,
     "user": {
      "displayName": "Zhongqi Gao",
      "userId": "11577090512157430756"
     },
     "user_tz": 300
    },
    "id": "O8eKNX76QIPZ",
    "outputId": "26780ab5-7865-4b32-cd56-a251214b1181"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEV = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "error",
     "timestamp": 1681777229212,
     "user": {
      "displayName": "Zhongqi Gao",
      "userId": "11577090512157430756"
     },
     "user_tz": 300
    },
    "id": "WxSYJna5V2T1",
    "outputId": "8ebcab9f-0adc-4c57-9460-e62e5f06291b"
   },
   "outputs": [],
   "source": [
    "class AdaptiveVectorNavigation():\n",
    "    def __init__(self, \n",
    "                 forage_time: int, \n",
    "                 num_neurons: int,\n",
    "                 leak_rate  : float) -> None:\n",
    "        self.feeder_position = torch.randn((2,), device=DEV) # TODO: follow eqs 25, 26, 27\n",
    "        self.time = 0\n",
    "        self.forage_time = forage_time\n",
    "        self.reward_threshold = 10 # TODO: make real value\n",
    "\n",
    "        self.phi      = 0\n",
    "        self.speed    = 0\n",
    "        self.state    = True # outward trip initially\n",
    "        self.position = torch.zeros((2,), device=DEV) # (x,y)\n",
    "        self.rewards  = 0\n",
    "    \n",
    "        self.neuron_phi            = (2 * torch.pi / num_neurons) * torch.arange(num_neurons, device=DEV)\n",
    "        self.cosine_kernel         = torch.empty((num_neurons, num_neurons), device=DEV)\n",
    "        for i in range(num_neurons):\n",
    "            for j in range(num_neurons):\n",
    "                self.cosine_kernel[i,j] = torch.cos(self.neuron_phi[i] - self.neuron_phi[j])\n",
    "        self.decoding_layer           = torch.zeros((num_neurons,), device=DEV)\n",
    "        self.previous_memory_layer    = torch.zeros((num_neurons,), device=DEV)\n",
    "        self.leak_rate                = leak_rate\n",
    "        self.home_vector              = torch.zeros((num_neurons,), device=DEV)\n",
    "        self.global_vector            = torch.zeros((num_neurons,), device=DEV)\n",
    "        self.learning_rate            = 2 # mu = 2 by default. can change. \n",
    "        self.inverse_temp_exploration = 0.1 # guess at a good initial value\n",
    "        self.lpf_food_reward          = 0\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def update_home_vector(self) -> None:\n",
    "        head_layer = torch.cos(self.phi - self.neuron_phi)\n",
    "        gating_layer = self.relu(head_layer - 1 + self.speed)\n",
    "        memory_layer = self.relu(gating_layer + ((1 - self.leak_rate) * self.previous_memory_layer))\n",
    "        self.previous_memory_layer = memory_layer\n",
    "        self.decoding_layer = self.relu(torch.matmul(self.cosine_kernel, memory_layer)) # actually the head vector\n",
    "        head_vector_angle = torch.atan(torch.dot(self.decoding_layer, torch.sin(self.neuron_phi)) / torch.dot(self.decoding_layer, torch.cos(self.neuron_phi)))\n",
    "        head_vector_length = torch.sum(self.decoding_layer) # could be incorrect implementation, hard to understand article\n",
    "        self.motor_hv = head_vector_length * torch.sin(head_vector_angle - self.phi - torch.pi)\n",
    "\n",
    "    def update_global_vector(self) -> None:\n",
    "        global_layer = torch.cos(self.phi - self.neuron_phi)\n",
    "        print(f\"global layer1: {global_layer}\")\n",
    "        self.state = (self.time < self.forage_time) and (self.rewards < self.reward_threshold) # inward/outward trip\n",
    "        \n",
    "        self.rewards = self.relu(1 - 5 * torch.norm(self.feeder_position - self.position)) \n",
    "        global_layer = int(self.state) * self.global_vector\n",
    "        print(f\"global layer: {global_layer}\")\n",
    "        delta_global_vector = self.learning_rate * self.rewards * int(self.state) * (self.decoding_layer - global_layer) # equation 14 and 15. \n",
    "        self.global_vector += delta_global_vector \n",
    "        \n",
    "        global_vector_angle = torch.atan(torch.dot(global_layer, torch.sin(self.neuron_phi)) / torch.dot(global_layer, torch.cos(self.neuron_phi)))\n",
    "        global_vector_length = torch.sum(self.global_vector) # todo: unsure\n",
    "        print(f\"global vec angle/length: {global_vector_angle, global_vector_length}\")\n",
    "        self.motor_gv = global_vector_length * torch.sin(global_vector_angle - self.phi) #todo: global vector angle?\n",
    "        \n",
    "\n",
    "        global_vector_length = torch.sum(self.global_vector) # todo: unsure\n",
    "        global_vector_angle = torch.atan(torch.dot(self.global_vector, torch.sin(self.neuron_phi)) / torch.dot(self.global_vector, torch.cos(self.neuron_phi)))\n",
    "        self.motor_gv = global_vector_length * torch.sin(global_vector_angle - self.phi) #todo: global vector angle?\n",
    "\n",
    "    def update_navigation(self) -> None:\n",
    "        # update sensory input\n",
    "        # self.phi, self.speed, self.state, and self.rewards\n",
    "        self.speed = 1 # TODO: make based on change in position over time\n",
    "        \n",
    "        self.update_home_vector()\n",
    "\n",
    "        self.update_global_vector()\n",
    "\n",
    "        # update exploration and navigation\n",
    "        exploration_rate = int(self.state) * np.exp(-self.inverse_temp_exploration * self.lpf_food_reward) #todo: equation 19\n",
    "        random_search = torch.normal(0.0, exploration_rate, (1,), device=DEV)\n",
    "        self.lpf_food_reward = self.rewards + 0.995 * self.lpf_food_reward\n",
    "        print(f\"lpf food reward: {self.lpf_food_reward}\")\n",
    "        self.inverse_temp_exploration += 1e-6 * ((1 / self.inverse_temp_exploration) + (100 * self.lpf_food_reward * exploration_rate))\n",
    "        print(f\"inverse temp of exploration {self.inverse_temp_exploration}\")\n",
    "        motor_command = (1 - exploration_rate) * ((int(self.state) * self.motor_gv) + self.motor_hv) + random_search\n",
    "        print(f\"motor gv/hv: {self.motor_gv, self.motor_hv}\")\n",
    "\n",
    "        # update position due to control input\n",
    "        self.phi += 0.1 * torch.pi * motor_command # 0.1 = Delta t\n",
    "        self.position[0] += 0.1 * self.lpf_food_reward * torch.cos(self.phi)\n",
    "        self.position[1] += 0.1 * self.lpf_food_reward * torch.sin(self.phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_test_navigation = AdaptiveVectorNavigation(1000, 18, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global layer1: tensor([ 1.0000,  0.9397,  0.7660,  0.5000,  0.1736, -0.1736, -0.5000, -0.7660,\n",
      "        -0.9397, -1.0000, -0.9397, -0.7660, -0.5000, -0.1736,  0.1736,  0.5000,\n",
      "         0.7660,  0.9397], device='cuda:0')\n",
      "global layer: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0')\n",
      "global vec angle/length: (tensor(nan, device='cuda:0'), tensor(0., device='cuda:0'))\n",
      "lpf food reward: 0.0\n",
      "inverse temp of exploration 0.10001000016927719\n",
      "motor gv/hv: (tensor(nan, device='cuda:0'), tensor(2.2655e-06, device='cuda:0'))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [] doesn't match the broadcast shape [1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m position_sequence \u001b[38;5;241m=\u001b[39m [graph_test_navigation\u001b[38;5;241m.\u001b[39mposition]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2000\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mgraph_test_navigation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_navigation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     position_sequence\u001b[38;5;241m.\u001b[39mappend(graph_test_navigation\u001b[38;5;241m.\u001b[39mposition)\n",
      "Cell \u001b[1;32mIn[66], line 85\u001b[0m, in \u001b[0;36mAdaptiveVectorNavigation.update_navigation\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# update position due to control input\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphi \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m*\u001b[39m motor_command \u001b[38;5;66;03m# 0.1 = Delta t\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlpf_food_reward \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mcos(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphi)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlpf_food_reward \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphi)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: output with shape [] doesn't match the broadcast shape [1]"
     ]
    }
   ],
   "source": [
    "position_sequence = [graph_test_navigation.position]\n",
    "for _ in range(2000):\n",
    "    graph_test_navigation.update_navigation()\n",
    "    position_sequence.append(graph_test_navigation.position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
